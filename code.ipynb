{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loadSubtitle import loadSubtitle\n",
    "import Extraction \n",
    "from importlib import reload\n",
    "import string\n",
    "import csv\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = loadSubtitle()\n",
    "seasons, file_adresess = load.loadseasons('english')\n",
    "load.process_subtitles('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/donya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/donya/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "reload(Extraction)\n",
    "WordExtraction = Extraction.Model()\n",
    "path = 'english/season 1/Friends - 1x01 - The One Where Monica Gets A Roommate.SAiNTS.en.srt'\n",
    "matches, dialogues, start_times, end_times  = WordExtraction.DialogueExtraction(path)\n",
    "\n",
    "tag, time = WordExtraction.tag(path)\n",
    "translateds = []\n",
    "initialwords = []\n",
    "meanings = []\n",
    "example_sentences = []\n",
    "\n",
    "new_dialogues = WordExtraction.RemovePuncs(dialogues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dialogues"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pilot season 1 episode 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/donya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/donya/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "reload(Extraction)\n",
    "\n",
    "\n",
    "WordExtraction = Extraction.Model()\n",
    "\n",
    "filtered_words = []\n",
    "\n",
    "for i in range(len(new_dialogues)):\n",
    "    filtered_word = WordExtraction.WordFilter(new_dialogues[i])\n",
    "    filtered_words.append(filtered_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/donya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/donya/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "reload(Extraction)\n",
    "\n",
    "\n",
    "WordExtraction = Extraction.Model()\n",
    "\n",
    "initialwords = []\n",
    "\n",
    "for i in range(len(new_dialogues)):\n",
    "\n",
    "    initialwords.append(WordExtraction.WordFilter(new_dialogues[i]))\n",
    "    initialwords = [x for x in initialwords if x]\n",
    "initialwords = list(itertools.chain(*initialwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['the', 'god','of', 'and', 'to', 'a', 'in', 'that', 'is', 'for', 'it', 'with', 'was', 'as', 'be', 'on', 'not', 'he',\n",
    "         'by', 'are', 'this', 'or', 'from', 'but', 'have', 'an', 'they', 'which', 'one', 'you', 'were', 'her', 'all',\n",
    "         'she', 'there', 'would', 'their', 'we', 'him', 'been', 'has', 'when', 'who', 'will', 'more', 'no', 'if',\n",
    "         'out', 'so', 'said', 'what', 'up', 'its', 'about', 'into', 'than', 'them', 'can', 'only', 'other', 'new',\n",
    "         'some', 'could', 'these', 'two', 'may', 'then', 'do', 'first', 'any', 'my', 'now', 'such', 'like', 'our',\n",
    "         'over', 'man', 'me', 'even', 'most', 'made', 'after', 'also', 'did', 'many', 'before', 'must', 'through',\n",
    "         'back', 'years', 'where', 'much', 'your', 'way', 'well', 'down', 'should', 'because', 'each', 'just', 'those',\n",
    "         'people', 'mr', 'how', 'too', 'little', 'state', 'good', 'very', 'make', 'world', 'still', 'own', 'see',\n",
    "         'men', 'work', 'long', 'get', 'here', 'between', 'both', 'life', 'being', 'under', 'never', 'day', 'same',\n",
    "         'another', 'know', 'while', 'last', 'might', 'us', 'great', 'old', 'year', 'off', 'come', 'since', 'against',\n",
    "         'go', 'came', 'right', 'used', 'take', 'three', 'without', 'just', 'every', 'think', 'don\\'t', 'might',\n",
    "         'place', 'end', 'again', 'home', 'himself', 'away', 'part', 'went', 'old', 'want', 'school', 'children',\n",
    "         'number', 'very', 'she', 'her', 'way', 'even', 'year', 'great', 'such', 'before', 'must', 'went', 'came',\n",
    "         'own', 'work', 'last', 'many', 'know', 'where', 'these', 'back', 'take', 'through', 'off', 'left', 'under',\n",
    "         'also', 'might', 'something', 'went', 'went', 'why', 'look', 'want', 'few', 'never', 'house', 'place', 'year',\n",
    "         'thing', 'every', 'small', 'woman', 'man', 'new', 'life', 'same', 'child', 'work', 'know', 'try', 'hand',\n",
    "         'every', 'number', 'page', 'should', 'country', 'found', 'answer', 'found', 'sound', 'study', 'still',\n",
    "         'learn', 'plant', 'cover', 'food', 'sun', 'four', 'between', 'state', 'keep', 'eye', 'never', 'last',\n",
    "         'let', 'thought', 'city', 'tree', 'cross','about', 'above', 'after', 'again', 'all', 'almost', 'along', 'also', 'always', 'among', 'and', \n",
    "         'another', 'any', 'anything', 'are', 'around', 'as', 'at', 'back', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'big', 'both', 'but', 'by', 'call', 'can', \n",
    "         'come', 'could', 'day', 'did', 'different', 'do', 'does', 'don\\'t', 'down', 'each', 'end', 'even', 'every', 'few', 'find', 'first', 'for', 'found', 'from', 'get', 'give', 'go', 'good', 'great', 'had', 'has', 'have', 'he', 'help', 'her', 'here', 'him', 'his', 'how', 'I', 'if', 'in', 'into', 'is', 'it', 'its', 'just', 'know', 'large', 'last', 'left', 'like', 'little', 'long', 'look', 'made', 'make', 'many', \n",
    "         'may', 'me', 'men', 'might', 'more', 'most', 'much', 'must', 'my', 'never', 'new', 'no', 'not', 'now', 'of', 'off', 'old', 'on', 'once', 'one', 'only', 'or', 'other', 'our', 'out', 'over', 'own', 'part', 'people', 'place', 'put', 'read', \n",
    "         'right', 'said', 'same', 'saw', 'say', 'see', 'she', 'should', 'show', 'small', 'so', 'some', 'something', 'sound', 'still', 'such', 'take', 'tell', 'than', 'that', 'the', 'them', 'then', 'there', 'these', 'they', 'thing', 'think', 'this', 'those', 'thought', 'three', 'through',\n",
    "          'time', 'to', 'together', 'too', 'two', 'under', 'up', 'us', 'use', 'very', 'want', 'was', 'way', 'we', 'well', 'went', 'were', 'what', 'when', 'where', 'which', 'while', 'who', 'why', 'will', 'with', 'without', 'woman', 'work', 'would', 'year', 'you', 'young', 'your','a', 'able', 'about', 'above', 'accept', 'according', 'account', 'across', 'act', 'action', 'active', 'activity', 'actually', 'add', 'address', 'administration', 'admit', 'adult', 'affect', 'after', 'again', 'against', 'age', 'agency', 'agent', 'ago', 'agree', 'agreement', 'ahead', 'air', 'all', 'allow', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'amazing', 'american', 'among', 'amount', 'analysis', 'and', 'animal', 'another', 'answer', 'any', 'anyone', 'anything', 'appear', 'approach', 'area', 'argue', 'arm', 'around', 'arrive', 'art', 'article', 'artist', 'as', 'ask', 'assume', 'at', 'attack', 'attention', 'attorney', 'audience', 'author', 'authority', 'available', 'avoid', 'away', 'baby', 'back', 'bad', 'bag', 'ball', 'bank', 'bar', 'base', 'be', 'beat', 'beautiful', 'because', 'become', 'bed', 'before', 'begin', 'behavior', 'behind', 'believe', 'benefit', 'best', 'better', 'between', 'beyond', 'big', 'bill', 'billion', 'bit', 'black', 'blood', 'blue', 'board', 'body', 'book', 'born', 'both', 'box', 'boy', 'break', 'bring', 'brother', 'budget', 'build', 'building', 'business', 'but', 'buy', 'by', 'call', 'camera', 'campaign', 'can', 'cancer', 'candidate', 'capital', 'car', 'card', 'care', 'career', 'carry', 'case', 'catch', 'cause', 'cell', 'center', 'central', 'century', 'certain', 'certainly', 'chair', 'challenge', 'chance', 'change', 'character', 'charge', 'check', 'child', 'choice', 'choose', 'church', 'citizen', 'city', 'civil', 'claim', 'class', 'clear', 'clearly', 'close', 'coach', 'cold', 'collection', 'college', 'color', 'come', 'commercial', 'common', 'community', 'company', 'compare', 'computer', 'concern', 'condition', 'conference', 'Congress', 'consider', 'consumer', 'contain', 'continue', 'control', 'cost', 'could', 'country', 'couple', 'course', 'court', 'cover', 'create', 'crime', 'cultural', 'culture', 'cup', 'current', 'customer', 'cut', 'dark', 'data', 'daughter', 'day', 'dead', 'deal', 'death', 'debate', 'decade', 'decide', 'decision', 'deep', 'defense', 'degree', 'democrat', 'demonstrate', 'design', 'despite', 'detail', 'determine', 'develop', 'development', 'die', 'difference', 'different', 'difficult', 'dinner', 'direction', 'director', 'discover', 'discuss', 'discussion', 'disease', 'do', 'doctor', 'dog', 'door',\n",
    "        'baby', 'bird', 'blue', 'book', 'box', 'boy', 'bread', 'cake', 'car', 'cat', 'city', 'day', 'dog', 'door', 'duck', 'egg', 'eye', 'farmer', 'fish', 'flower', 'food', 'frog', 'girl', 'grass', 'hand', 'hat', 'head', 'hill', 'home', 'house', 'ink', 'job', 'juice', 'king', 'kite', 'leaf', 'leg', 'letter', 'light', 'lion', 'man', 'map', 'milk', 'money', 'moon', 'morning', 'mother', 'music', 'name', 'nest', 'night', 'nose', 'orange', 'paper', 'party', 'pen', 'pencil', 'person', 'picture', 'pie', 'pig', 'plant', 'play', 'rabbit', 'rain', 'ring', 'river', 'road', 'rock', 'room', 'rose', 'school', 'seed', 'sheep', 'shoe', 'shop', 'show', 'singer', 'sister', 'sky', 'snow', 'song', 'sound', 'star', 'street', 'sun', 'table', 'teacher', 'thing', 'time', 'toe', 'tree', 'water', 'way', 'web', 'wind', 'window', 'woman', 'wood', 'word', 'world', 'year', 'yellow',\n",
    "'apple', 'banana', 'car', 'dog', 'elephant', 'fox', 'grape', 'hat', 'igloo', 'jacket', 'kangaroo', 'lemon', 'monkey', 'notebook', 'orange', 'pear', 'queen', 'rabbit', 'sun', 'table', 'umbrella', 'violin', 'water', 'xylophone', 'yak', 'zebra', 'ant', 'boat', 'cat', 'duck', 'egg', 'fish', 'goose', 'horse', 'ink', 'jungle', 'key', 'lion', 'mango', 'night', 'owl', 'pizza', 'quilt', 'rose', 'snake', 'tree', 'unicorn', 'van', 'window', 'xylophone', 'yarn', 'zealot', 'airplane', 'bag', 'computer', 'desk', 'ear', 'football', 'guitar', 'hat', 'ice', 'juice', 'kite', 'lion', 'money', 'note', 'pencil', 'queen', 'rain', 'snake', 'table', 'umbrella', 'vase', 'watch', 'xylophone', 'yacht', 'zeppelin', 'bee', 'carrot', 'dog', 'elephant', 'frog', 'goat', 'hamster', 'igloo', 'jellyfish', 'koala', 'lizard', 'moon', 'nest', 'octopus', 'penguin', 'quail', 'rooster', 'shark', \n",
    "'turtle', 'umbrella', 'volcano', 'watermelon', 'xylophone', 'yak', 'zebra', 'air', 'balloon', 'cat', 'donkey', 'eggplant', 'frog', 'grass', 'hamster', 'igloo', 'jacket', 'kite', 'laptop', 'monkey', 'nail', 'orange', 'panda', 'quiche', 'rabbit', 'star', 'tiger', 'unicorn', 'violin', 'water', 'xylophone', 'yogurt', 'zealot'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(Extraction)\n",
    "WordExtraction = Extraction.Model()\n",
    "\n",
    "initialwords = list(initialwords)\n",
    "wordcount = 0\n",
    "\n",
    "with open('translations.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['Word', 'Translation', 'Meaning', 'Example Sentence', 'Tag', 'Dialogue', 'Start Time', 'End Time']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for i in range(len(new_dialogues)):\n",
    "        for word in initialwords[i]:\n",
    "            wordcount += 1\n",
    "            \n",
    "            try:\n",
    "                translated, meaning = WordExtraction.Translator(word)\n",
    "                example = WordExtraction.Example(word)\n",
    "\n",
    "                writer.writerow({\n",
    "                    'Word': word,\n",
    "                    'Translation': translated,\n",
    "                    'Meaning': meaning,\n",
    "                    'Example Sentence': example,\n",
    "                    'Tag' : tag,\n",
    "                    'Dialogue' : dialogues[i],\n",
    "                    'Start Time' : start_times[i],\n",
    "                    'End Time' : end_times[i]\n",
    "                })\n",
    "            except Exception as e:\n",
    "                \n",
    "                print(f\"Error occurred while translating word '{word}': {e}\")\n",
    "                continue  # Skip to the next word if translation fails\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from Extraction import Model\n",
    "\n",
    "WordExtraction = Model()\n",
    "\n",
    "initialwords = set()\n",
    "\n",
    "for i in range(len(new_dialogues)):\n",
    "    filtered_words = WordExtraction.WordFilter(new_dialogues[i])\n",
    "    filtered_tuple = tuple(filtered_words)\n",
    "    initialwords.add(filtered_tuple)\n",
    "\n",
    "# Convert set to list and eliminate duplicates\n",
    "initialwords = list(set(initialwords))\n",
    "\n",
    "wordcount = 0\n",
    "\n",
    "with open('new.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['Word', 'Translation', 'Meaning', 'Example Sentence', 'Tag', 'Dialogue', 'Start Time', 'End Time']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for i in range(len(new_dialogues)):\n",
    "        for word in initialwords:\n",
    "            wordcount += 1\n",
    "            try:\n",
    "                translated, meaning = WordExtraction.Translator(word)\n",
    "                example = WordExtraction.Example(word)\n",
    "\n",
    "                writer.writerow({\n",
    "                    'Word': word,\n",
    "                    'Translation': translated,\n",
    "                    'Meaning': meaning,\n",
    "                    'Example Sentence': example,\n",
    "                    'Tag' : tag,\n",
    "                    'Dialogue' : dialogues[i],\n",
    "                    'Start Time' : start_times[i],\n",
    "                    'End Time' : end_times[i]\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred while translating word '{word}': {e}\")\n",
    "                continue  # Skip to the next word if translation fails\n",
    "\n",
    "print(wordcount)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
