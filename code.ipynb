{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/donya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/donya/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from loadSubtitle import loadSubtitle\n",
    "import Extraction \n",
    "from importlib import reload\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = loadSubtitle()\n",
    "seasons, file_adresess = load.loadseasons('english')\n",
    "load.process_subtitles('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/donya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/donya/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "reload(Extraction)\n",
    "WordExtraction = Extraction.Model()\n",
    "path = 'english/season 1/Friends - 1x01 - The One Where Monica Gets A Roommate.SAiNTS.en.srt'\n",
    "matches, dialogues, start_times, end_times  = WordExtraction.DialogueExtraction(path)\n",
    "\n",
    "tag, time = WordExtraction.tag(path)\n",
    "translateds = []\n",
    "initialwords = []\n",
    "meanings = []\n",
    "example_sentences = []\n",
    "\n",
    "new_dialogues = WordExtraction.RemovePuncs(dialogues)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pilot season 1 episode 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/donya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/donya/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m initialwords \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[1;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(new_dialogues)):\n\u001b[0;32m----> 8\u001b[0m     initialwords\u001b[39m.\u001b[39;49madd(WordExtraction\u001b[39m.\u001b[39;49mWordFilter(new_dialogues[i]))\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "reload(Extraction)\n",
    "\n",
    "\n",
    "WordExtraction = Extraction.Model()\n",
    "initialwords = set()\n",
    "\n",
    "for i in range(len(new_dialogues)):\n",
    "    initialwords.add(WordExtraction.WordFilter(new_dialogues[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/donya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/donya/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n"
     ]
    },
    {
     "ename": "NotValidPayload",
     "evalue": "630 --> text must be a valid text with maximum 5000 character, otherwise it cannot be translated",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotValidPayload\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(new_dialogues)):\n\u001b[1;32m     11\u001b[0m     \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m initialwords[i]:\n\u001b[0;32m---> 12\u001b[0m         translated, meaning \u001b[39m=\u001b[39m WordExtraction\u001b[39m.\u001b[39;49mTranslator(word)\n\u001b[1;32m     13\u001b[0m         example \u001b[39m=\u001b[39m WordExtraction\u001b[39m.\u001b[39mExample(word)\n\u001b[1;32m     16\u001b[0m         writer\u001b[39m.\u001b[39mwriterow({\n\u001b[1;32m     17\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mWord\u001b[39m\u001b[39m'\u001b[39m: word,\n\u001b[1;32m     18\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mTranslation\u001b[39m\u001b[39m'\u001b[39m: translated,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mEndTime\u001b[39m\u001b[39m'\u001b[39m : end_times[i]\n\u001b[1;32m     25\u001b[0m         })\n",
      "File \u001b[0;32m~/Documents/study room/Extraction.py:594\u001b[0m, in \u001b[0;36mModel.Translator\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mTranslator\u001b[39m(\u001b[39mself\u001b[39m, word):\n\u001b[1;32m    592\u001b[0m     dictionary \u001b[39m=\u001b[39m PyDictionary()\n\u001b[0;32m--> 594\u001b[0m     translated \u001b[39m=\u001b[39m GoogleTranslator(source\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mauto\u001b[39;49m\u001b[39m'\u001b[39;49m, target\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mfa\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mtranslate(word)\n\u001b[1;32m    595\u001b[0m     meaning \u001b[39m=\u001b[39m dictionary\u001b[39m.\u001b[39mmeaning(word)\n\u001b[1;32m    597\u001b[0m     \u001b[39mreturn\u001b[39;00m translated, meaning\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/deep_translator/google.py:57\u001b[0m, in \u001b[0;36mGoogleTranslator.translate\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtranslate\u001b[39m(\u001b[39mself\u001b[39m, text: \u001b[39mstr\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m     52\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[39m    function to translate a text\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[39m    @param text: desired text to translate\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[39m    @return: str: translated text\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     \u001b[39mif\u001b[39;00m is_input_valid(text):\n\u001b[1;32m     58\u001b[0m         text \u001b[39m=\u001b[39m text\u001b[39m.\u001b[39mstrip()\n\u001b[1;32m     59\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_same_source_target() \u001b[39mor\u001b[39;00m is_empty(text):\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/deep_translator/validate.py:22\u001b[0m, in \u001b[0;36mis_input_valid\u001b[0;34m(text, min_chars, max_chars)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39mvalidate the target text to translate\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m@param min_chars: min characters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39m@return: bool\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(text, \u001b[39mstr\u001b[39m) \u001b[39mor\u001b[39;00m text\u001b[39m.\u001b[39misdigit():\n\u001b[0;32m---> 22\u001b[0m     \u001b[39mraise\u001b[39;00m NotValidPayload(text)\n\u001b[1;32m     23\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m min_chars \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(text) \u001b[39m<\u001b[39m max_chars:\n\u001b[1;32m     24\u001b[0m     \u001b[39mraise\u001b[39;00m NotValidLength(text, min_chars, max_chars)\n",
      "\u001b[0;31mNotValidPayload\u001b[0m: 630 --> text must be a valid text with maximum 5000 character, otherwise it cannot be translated"
     ]
    }
   ],
   "source": [
    "reload(Extraction)\n",
    "import csv\n",
    "WordExtraction = Extraction.Model()\n",
    "\n",
    "\n",
    "with open('translations.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['Word', 'Translation', 'Meaning', 'Example Sentence', 'Tag', 'Dialogue', 'Start Time', 'End Time']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for i in range(len(new_dialogues)):\n",
    "        for word in initialwords[i]:\n",
    "            translated, meaning = WordExtraction.Translator(word)\n",
    "            example = WordExtraction.Example(word)\n",
    "\n",
    "        \n",
    "            writer.writerow({\n",
    "                'Word': word,\n",
    "                'Translation': translated,\n",
    "                'Meaning': meaning if meaning else 'N/A',\n",
    "                'Example Sentence': example if example else 'N/A',\n",
    "                'Tag' : tag,\n",
    "                'Dialouge' : dialogues[i],\n",
    "                'StartTime' : start_times[i],\n",
    "                'EndTime' : end_times[i]\n",
    "            })\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
