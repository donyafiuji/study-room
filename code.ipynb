{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loadSubtitle import loadSubtitle\n",
    "import Extraction \n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = loadSubtitle()\n",
    "seasons, file_adresess = load.loadseasons('english')\n",
    "load.process_subtitles('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_marks = ['.', ',', '?', '!', ':', ';', '\"', \"'\", '-', '—', '(', ')', '[', ']', '{', '}', '...', '/',\n",
    "                '\\\\', '&', '@', '#', '$', '%', '^', '*', '+', '=', '<', '>', '_', '|','..',\"'s\",\"'re\",\"'ll\",'INC',\"''\"\n",
    "                ,'Hi']\n",
    "\n",
    "parent_dir = 'english'\n",
    "for season in range(1, 11):\n",
    "\n",
    "    season_dir = f'{parent_dir}/season {season}'\n",
    "    for filename in glob.glob(f'{season_dir}/*.srt'):\n",
    "        with open(filename, 'r+', encoding='ISO-8859-1') as file:\n",
    "\n",
    "            # filters out the characters\n",
    "            content = file.read()\n",
    "\n",
    "    # Remove special characters from subtitle text\n",
    "            for char in punctuation_marks:\n",
    "                content = content.replace(char, '')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pilot season 1 episode 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/donya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/donya/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: HTTPConnectionPool(host='wordnetweb.princeton.edu', port=80): Max retries exceeded with url: /perl/webwn?s=phone (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f6d1039e880>: Failed to establish a new connection: [Errno 110] Connection timed out'))\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Following Error occured: list index out of range\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[118], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39m# Translation\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(dialogues)):\n\u001b[0;32m---> 16\u001b[0m     translated, initialword, meaning, example_sentence \u001b[39m=\u001b[39m WordExtraction\u001b[39m.\u001b[39;49mTranslator(dialogues[i])\n\u001b[1;32m     17\u001b[0m     translateds\u001b[39m.\u001b[39mappend(translated)\n\u001b[1;32m     18\u001b[0m     initialwords\u001b[39m.\u001b[39mappend(initialword)\n",
      "File \u001b[0;32m~/Documents/study room/Extraction.py:585\u001b[0m, in \u001b[0;36mModel.Translator\u001b[0;34m(self, dialogues)\u001b[0m\n\u001b[1;32m    582\u001b[0m     example_sentences\u001b[39m.\u001b[39mappend(examples)\n\u001b[1;32m    584\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 585\u001b[0m     first_synset \u001b[39m=\u001b[39m synsets[\u001b[39m1\u001b[39;49m]\n\u001b[1;32m    586\u001b[0m     examples \u001b[39m=\u001b[39m first_synset\u001b[39m.\u001b[39mexamples()\n\u001b[1;32m    587\u001b[0m     \u001b[39mif\u001b[39;00m examples:\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "reload(Extraction)\n",
    "WordExtraction = Extraction.Model()\n",
    "path = 'english/season 1/Friends - 1x01 - The One Where Monica Gets A Roommate.SAiNTS.en.srt'\n",
    "matches, dialogues, start_times, end_times  = WordExtraction.DialogueExtraction(path)\n",
    "\n",
    "tag, time = WordExtraction.tag(path)\n",
    "translateds = []\n",
    "initialwords = []\n",
    "meanings = []\n",
    "example_sentences = []\n",
    "\n",
    "# Translation\n",
    "for i in range(len(dialogues)):\n",
    "\n",
    "\n",
    "    translated, initialword, meaning, example_sentence = WordExtraction.Translator(dialogues[i])\n",
    "    translateds.append(translated)\n",
    "    initialwords.append(initialword)\n",
    "    meanings.append(meaning)\n",
    "    example_sentences.append(example_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['وجود دارد', 'بگو', 'پسر', 'کار کردن', 'با.'] [\"there's\", 'tell.', 'guy', 'work', 'with.'] [{'Noun': ['a location other than here; that place']}, None, {'Noun': ['an informal term for a youth or man', 'an effigy of Guy Fawkes that is burned on a bonfire on Guy Fawkes Day', 'a cable, wire, or rope that is used to brace something (especially a tent'], 'Verb': ['subject to laughter or ridicule', 'steady or support with a guy wire or cable']}, {'Noun': ['activity directed toward making or doing something', 'a product produced or accomplished through the effort or activity or agency of a person or thing', 'the occupation for which you are paid', 'applying the mind to learning and understanding a subject (especially by reading', '(physics', 'a place where work is done', 'the total output of a writer or artist (or a substantial part of it'], 'Verb': ['exert oneself by doing mental or physical work for a purpose or out of necessity', 'be employed', 'have an effect or outcome; often the one desired or expected', 'perform as expected when applied', 'shape, form, or improve a material', 'give a workout to', 'proceed along a path', 'operate in a certain place, area, or specialty', 'proceed towards a goal or along a path or through an activity', 'move in an agitated manner', 'cause to happen or to occur as a consequence', 'cause to work', 'prepare for crops', 'behave in a certain way when handled', 'have and exert influence or effect', 'operate in or through', 'cause to operate or function', 'provoke or excite', 'gratify and charm, usually in order to influence', 'make something, usually for a specific function', 'move into or onto', 'make uniform', \"use or manipulate to one's advantage\", 'find the solution to (a problem or question', 'cause to undergo fermentation', 'go sour or spoil', 'arrive at a certain condition through repeated motion']}, None] ['', '', ['a nice guy', \"the guy's only doing it for some doll\"], ['she checked several points needing further work'], '']\n"
     ]
    }
   ],
   "source": [
    "print(translated, initialword, meaning, example_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n",
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(filtered_words))\n",
    "print(len(translated))\n",
    "print(len(meaning))\n",
    "print(len(example_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_words = [\"there's\", 'tell.', 'guy', 'work', 'with.']\n",
    "for word in filtered_words:\n",
    "\n",
    "    synsets = wordnet.synsets(word)\n",
    "\n",
    "    if synsets:\n",
    "        first_synset = synsets[0]\n",
    "        examples = first_synset.examples()\n",
    "        if examples:\n",
    "            example_sentences.append(examples)\n",
    "            # print(\"Examples for '{}':\".format(word))\n",
    "            # for example in examples[:2]:  # Print first 2 examples\n",
    "            #     print(\"- {}\".format(example))\n",
    "        else:\n",
    "            first_synset = synsets[2]\n",
    "            examples = first_synset.examples()\n",
    "            example_sentences.append(examples)\n",
    "            # print(\"Examples for '{}':\".format(word))\n",
    "            # for example in examples[:2]:  # Print first 2 examples\n",
    "            #     print(\"- {}\".format(example))\n",
    "    else:\n",
    "        example_sentences.append('')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples for 'tell':\n",
      "- Tell them that you will be late\n"
     ]
    }
   ],
   "source": [
    "synsets = wordnet.synsets('tell')\n",
    "\n",
    "if synsets:\n",
    "    first_synset = synsets[0]\n",
    "    examples = first_synset.examples()\n",
    "    if examples:\n",
    "        example_sentences.append(examples)\n",
    "        print(\"Examples for '{}':\".format(word))\n",
    "        for example in examples[:2]:  # Print first 2 examples\n",
    "            print(\"- {}\".format(example))\n",
    "    else:\n",
    "        synsets = wordnet.synsets('tell')\n",
    "        first_synset = synsets[2]\n",
    "        examples = first_synset.examples()\n",
    "        example_sentences.append(examples)\n",
    "        print(\"Examples for '{}':\".format('tell'))\n",
    "        for example in examples[:2]:  # Print first 2 examples\n",
    "            print(\"- {}\".format(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "data = [\n",
    "    (\"hello\", \"Season 1\", \"Episode 1\", \"Pilot\", \"00:05:23\"),\n",
    "    (\"world\", \"Season 1\", \"Episode 1\", \"Pilot\", \"00:05:23\"),\n",
    "    (\"goodbye\", \"Season 1\", \"Episode 2\", \"The Departure\", \"00:11:47\"),\n",
    "    (\"friend\", \"Season 1\", \"Episode 2\", \"The Departure\", \"00:11:47\")\n",
    "]\n",
    "\n",
    "with open(\"output.csv\", \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"Word\", \"Season\", \"Episode\", \"Title\", \"Timestamp\"])\n",
    "    for row in data:\n",
    "        writer.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
