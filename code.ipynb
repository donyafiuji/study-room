{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/donya/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/donya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/donya/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "2023-07-08 13:31:29.720762: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from loadSubtitle import loadSubtitle\n",
    "import Extraction \n",
    "from importlib import reload\n",
    "import string\n",
    "import csv\n",
    "import itertools\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = loadSubtitle()\n",
    "seasons, file_adresess = load.loadseasons('english')\n",
    "load.process_subtitles('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_dir = input('please enter the season name: ')\n",
    "file_adresess = []\n",
    "\n",
    "for filename in glob.glob(f'english/{season_dir}/*.srt'):\n",
    "    file_adresess.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/donya/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/donya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/donya/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "reload(Extraction)\n",
    "WordExtraction = Extraction.Model()\n",
    "path = 'english/season 1/Friends - 1x01 - The One Where Monica Gets A Roommate.SAiNTS.en.srt'\n",
    "matches, dialogues, start_times, end_times  = WordExtraction.DialogueExtraction(path)\n",
    "\n",
    "tag, time = WordExtraction.tag(path, 'season 1')\n",
    "translateds = []\n",
    "initialwords = []\n",
    "meanings = []\n",
    "example_sentences = []\n",
    "\n",
    "new_dialogues = WordExtraction.RemovePuncs(dialogues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(Extraction)\n",
    "WordExtraction = Extraction.Model()\n",
    "new_dialogues = []\n",
    "tags= []\n",
    "start_times = []\n",
    "end_times = []\n",
    "\n",
    "for path in file_adresess:\n",
    "\n",
    "    matches, dialogues, start_time, end_time = WordExtraction.DialogueExtraction(path)\n",
    "    start_times.append(start_time)\n",
    "    end_times.append(end_time)\n",
    "    tags.append(WordExtraction.tag(path)[0])\n",
    "    new_dialogues.append(WordExtraction.RemovePuncs(dialogues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialwords = []\n",
    "\n",
    "for dialogue in new_dialogues:\n",
    "    for i in range(len(dialogue)):\n",
    "        initialwords.append(WordExtraction.WordFilter(dialogue[i]))\n",
    "        initialwords = [x for x in initialwords if x]\n",
    "        # input(initialwords)\n",
    "initialwords = list(itertools.chain(*initialwords))\n",
    "input(initialwords)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pilot season 1 episode 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/donya/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/donya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/donya/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "reload(Extraction)\n",
    "\n",
    "\n",
    "WordExtraction = Extraction.Model()\n",
    "\n",
    "initialwords = []\n",
    "\n",
    "for i in range(len(new_dialogues)):\n",
    "\n",
    "    initialwords.append(WordExtraction.WordFilter(new_dialogues[i]))\n",
    "    initialwords = [x for x in initialwords if x]\n",
    "initialwords = list(itertools.chain(*initialwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "568\n",
      "390\n",
      "390\n",
      "390\n"
     ]
    }
   ],
   "source": [
    "print(len(initialwords))\n",
    "print(len(new_dialogues))\n",
    "print(len(start_times))\n",
    "print(len(end_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_dialogue_indices = {}\n",
    "word_to_starttime_indices = {}\n",
    "word_to_endtime_indices = {}\n",
    "\n",
    "for dialogue,start_time,end_time in zip(new_dialogues,start_times,end_times):\n",
    "    for word in initialwords:\n",
    "        if word in dialogue:\n",
    "            # if word not in word_to_dialogue_indices:\n",
    "            word_to_dialogue_indices[dialogue] = [word]\n",
    "            word_to_starttime_indices[start_time] = [word]\n",
    "            word_to_endtime_indices[end_time] = [word]\n",
    "            \n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Theres nothing to tell Its just some guy I work with': ['guy'], 'Youre going out with the guy': ['guy'], 'There has to be something wrong with him': ['im'], 'So does he have a hump and a hairpiece': ['hairpiece'], 'Wait does he eat chalk': ['chalk'], 'I dont want her to go through what I did with Carl': ['dont'], 'Okay everybody relax This is not even a date': ['date'], 'Sounds like a date to me': ['date'], 'Im in high school in the cafeteria': ['cafeteria'], 'and I realize Im totally naked': ['realize'], 'Then I look down and I realize there is a phone': ['phone'], 'All of a sudden the phone starts to ring': ['starts'], 'What do I do Everyone starts looking at me': ['looking'], 'They werent looking at you before': ['looking'], 'Finally I figure Id better answer it': ['figure'], 'And it turns out its my mother': ['turns'], 'Which is very very weird because she never calls me': ['calls'], 'He says Hello I want to kill myself': ['ill'], 'I feel like someone pulled my intestine out of my mouth': ['pulled'], ' and tied it around my neck  Cookie': ['tied'], 'Carol moved her stuff out today': ['stuff'], 'No dont Stop cleansing my aura': ['dont'], ' Just leave my aura alone okay  Fine be murky': ['murky'], ' Ill be fine I hope shell be happy  No you dont': ['dont'], 'No I dont To hell with her She left me': ['dont'], 'You never knew she was a lesbian': ['lesbian'], 'Why does everyone keep fixating on that': ['fixating'], 'She didnt know How should I know': ['didnt'], 'Sometimes I wish I was a lesbian': ['im'], 'Did I say that out loud': ['loud'], 'I told Mom and Dad last night They took it pretty well': ['las'], 'So that hysterical phone call from a woman sobbing': ['bing'], 'Ill never have grandchildren was what A wrong number': ['grandchildren'], 'Look youre feeling a lot of pain right now': ['youre'], 'Youre angry Youre hurting': ['hurting'], 'Strip joints': ['joints'], 'Hey youre single Have some hormones': ['youre'], 'But I dont want to be single okay': ['dont'], 'I just want to be married again': ['married'], 'And I just want a million dollars': ['ill'], 'and a guy with a hammer said youd be here and you are': ['guy'], 'Everybody this is Rachel a Lincoln High survivor': ['survivor'], 'You want to tell us now or are we waiting for four wet bridesmaids': ['bridesmaids'], 'Well it started about a halfhour before the wedding': ['started'], 'I was in the room with all the presents': ['presents'], 'and I was looking at this really gorgeous Limoges gravy boat': ['im'], 'Sweet N Low': ['wee'], 'I realized I was more turned on by this gravy boat than Barry': ['gravy'], 'I got freaked out and it hit me': ['freaked'], 'How much Barry looks like Mr Potato Head': ['looks'], 'I always knew he looked familiar but': ['familiar'], 'I had to get out of there and I started wondering': ['wondering'], 'I didnt know where to go and I know weve drifted apart': ['didnt'], 'but youre the only person I know here': ['youre'], ' Who wasnt invited to the wedding  I hoped that wouldnt be an issue': ['wasnt'], 'I guess he bought her the pipe organ and shes really not happy about it': ['guess'], 'Tuna or egg salad Decide': ['la'], 'Daddy I just I cant marry him': ['im'], 'Im sorry I just dont love him': ['im'], 'Well it matters to me': ['matters'], 'If I let go of my hair my head will fall off': ['ill'], 'She should not be wearing those pants': ['pants'], 'Push her down the stairs': ['stairs'], 'Push her Push her down the stairs': ['stairs'], 'All my life everyones always told me Youre a shoe': ['ones'], 'What if I dont want to be a shoe': ['dont'], 'What if I want to be a purse': ['purse'], 'No I dont want you to buy me a hat': ['dont'], 'Its a metaphor Daddy': ['metaphor'], 'You can see where hed have trouble': ['hed'], 'Well maybe Ill just stay here with Monica': ['maybe'], 'I guess weve established shes staying with Monica': ['guess'], 'Well maybe thats my decision': ['maybe'], 'Maybe I dont need your money': ['dont'], 'Wait I said maybe': ['maybe'], 'Try to think of nice calm things': ['things'], 'Raindrops on roses And whiskers on kittens': ['kittens'], 'Doorbells and sleigh bells And something with mittens': ['mittens'], 'La la la something And noodles with string': ['noodles'], 'I helped': ['helped'], 'Me and Chandler live across the hall Hes away a lot': ['ive'], 'Stop hitting on her Its her wedding day': ['hitting'], 'Like theres a rule or something': ['theres'], 'Please dont do that again Its a horrible sound': ['dont'], 'Oh God is it 630 Buzz him in': ['im'], ' Whos Paul  Paul the wine guy': ['guy'], 'Your not a real date is with Paul the wine guy': ['guy'], ' He finally asked you out  Yes': ['finally'], ' Rach I can cancel  Please go Ill be fine': ['cancel'], ' Really Go on Its Paul the wine guy': ['guy'], 'Or he just complains a lot': ['complains'], ' The wine guy  I didnt catch your name Paul': ['guy'], 'Ill be right back Ive just gotta go': ['gotta'], 'Change': ['hang'], 'Sit down Two seconds': ['seconds'], 'I just pulled out four eyelashes That cant be good': ['las'], 'Hey Paul heres a tip': ['heres'], 'She really likes it when you rub her neck in the same spot': ['spot'], 'until it starts to get red': ['starts'], 'I was supposed to be headed for Aruba on my honeymoon': ['supposed'], 'Right Youre not even getting your honeymoon': ['getting'], 'Although Aruba This time of year': ['im'], 'big lizards': ['liza'], 'If you dont want to be alone tonight': ['dont'], 'Joey and Chandler are helping me with my furniture': ['helping'], 'Thanks But Im just going to hang out here': ['hang'], 'I wish I could but I dont want to': ['dont'], 'Love is sweet as summer showers Love is a wondrous work of art': ['wee'], 'Is like a giant pigeon': ['pigeon'], 'Im supposed to attach a brackety thing to the side things': ['things'], 'using a bunch of these little worm guys': ['guy'], 'I have no brackety thing I see no worm guys whatsoever': ['guy'], 'and I cannot feel my legs': ['legs'], ' We got a bookcase  Its beautiful': ['bookcase'], 'I would have to say that is an Lshaped bracket': ['bracket'], ' Which goes where  I have no idea': ['goes'], ' Done with the bookcase  All finished': ['finished'], 'This was Carols favorite beer': ['favorite'], 'She always drank it out of the can I should have known': ['drank'], ' Start with that were out of here  Please dont spoil all this fun': ['dont'], 'She got the furniture the stereo the good TV': ['stereo'], 'What did you get': ['id'], ' You guys  You got screwed': ['guy'], ' Oh my God  I know Im such an idiot': ['idiot'], 'I shouldve known when she went to the dentist five times a week': ['im'], 'I mean how clean can teeth get': ['teeth'], 'My brothers going through that': ['brothers'], 'How did you get over it': ['id'], 'He might accidentally break something valuable of hers': ['valuable'], 'You actually broke her watch': ['broke'], 'The worst I ever did was shred my old boyfriends favorite towel': ['towel'], 'You probably think its about making love with your socks on but it isnt': ['isnt'], 'I know that some lucky girl is going to become Mrs Barry Finkel': ['lucky'], 'But it isnt me Its not me': ['isnt'], 'Not that I have any idea who me is right now but you just': ['id'], 'Im divorced': ['divorced'], ' Im only 26 and Im divorced  Shut up': ['divorced'], 'That only took me an hour': ['took'], 'We havent had a relationship thats lasted longer than a Mento': ['las'], 'Four years of closeness and sharing after which she ripped your heart out': ['ripped'], 'That is why we dont do it': ['dont'], 'I dont think that was my point': ['dont'], 'Know whats scary What if theres only one woman for everybody': ['theres'], 'I mean what if you get one woman and thats it': ['thats'], 'Unfortunately in my case there was only one woman for her': ['tuna'], 'What are you talking about One woman': ['talking'], 'Thats like saying theres only one flavor of ice cream': ['theres'], 'Let me tell you something Theres lots of flavors out there': ['heres'], 'Rocky road and cookie dough and bing cherry vanilla': ['ill'], 'You can get them with jimmies or nuts or whipped cream': ['im'], 'You got married You were like what 8': ['married'], ' I dont know if Im hungry or horny  Then stay out of my freezer': ['dont'], 'Ever since she walked out on me': ['walked'], 'You wanna spell it out with noodles': ['noodles'], 'Its more of a fifth date kind of revelation': ['date'], 'So theres going to be a fifth date': ['theres'], 'I havent been able to perform': ['perform'], 'sexually': ['sexually'], 'Being spit on is probably not what you need right now': ['spit'], 'Im glad you smashed her watch': ['smashed'], 'So you still think you might want that fifth date': ['ill'], 'We are gathered here to join Joanie Louise Cunningham': ['gathered'], 'in the bonds of holy matrimony': ['im'], 'But Joanie loved Chachi Thats the difference': ['loved'], 'Do you know how long its been since I grabbed a spoon': ['grabbed'], 'Do the words Billy dont be a hero mean anything to you': ['ill'], 'Great story But I gotta go': ['gotta'], 'I got a date with Andrea Angela No Andrea': ['date'], 'Andreas the screamer Angela has cats': ['scream'], 'Right thanks Its Julie Im out of here': ['thank'], ' That is amazing  Congratulations': ['la'], 'If I can make coffee there isnt anything I cant do': ['isnt'], 'I think its If I can invade Poland theres nothing I cant do': ['theres'], 'If you feel like you have to make a Western omelet or something': ['omelet'], 'Last night was like all my birthdays both graduations': ['graduations'], 'plus the barnraising scene in Witness': ['scene'], 'Well talk later': ['la'], 'That wasnt a real date': ['date'], 'What the hell do you do on a real date': ['date'], 'If I dont input those numbers it doesnt make much of a difference': ['dont'], 'So like you guys all have jobs': ['guy'], 'Yeah we all have jobs Thats how we buy stuff': ['stuff'], ' Yeah Im an actor  Have I seen you in anything': ['seen'], 'I doubt it Mostly regional work': ['regional'], 'Unless you saw the Wee Ones production of Pinocchio': ['production'], 'at the little theater in the park': ['theater'], 'Look Geppetto Im a real live boy': ['ive'], ' I will not take this abuse  Youre right Im sorry': ['ill'], 'Once I was a wooden boy A little wooden boy': ['wooden'], 'You should both know that hes a dead man': ['hes'], 'Did you talk to Barry I cant stop smiling': ['smiling'], 'I see that You look like you slept with a hanger in your mouth': ['hanger'], 'Well its like that With feelings': ['feelings'], ' Wow are you in trouble  Big time': ['im'], 'I think were getting a little ahead of ourselves': ['getting'], 'Im going to get up go to work and not think about him all day': ['im'], 'Im gonna go get one of those job things': ['things'], ' How was Florida  You had sex didnt you': ['didnt'], 'Im pushing my aunt through Parrot Jungle youre having sex': ['youre'], 'Paul the wine guy Yeah I know Paul': ['guy'], 'What I take credit for Paul': ['credit'], 'Before me there was no snap in his turtle for two years': ['snap'], 'Of course it was a line': ['line'], 'I assume we want an answer more sophisticated than': ['sophisticated'], 'Dont hate You dont want to put that out into the universe': ['dont'], 'Is it like I have some sort of beacon that only dogs': ['dogs'], 'and men with emotional problems can hear': ['problems'], 'Come here Give me your feet': ['ive'], 'I cant believe you didnt know it was a line': ['didnt'], 'Are you kidding Im trained for nothing': ['trained'], ' I was laughed out of 12 interviews  Youre surprisingly upbeat': ['upbeat'], 'Youd be too if you found these boots on sale': ['boots'], '002410215  002413275 How well you know me': ['002413275'], 'Theyre my I dont need a job': ['dont'], 'Ive got great boots boots': ['boots'], ' How did you pay  Credit card': ['id'], 'And who pays for that': ['pays'], 'Is this really necessary I can stop charging any time': ['im'], 'You cant live off your parents': ['parents'], 'I know that Thats why I was getting married': ['married'], 'Give her a break Its hard being on your own': ['ive'], 'Mom had killed herself stepdad was in jail': ['ill'], 'I didnt know anybody here': ['didnt'], 'I ended up living with this albino guy who was cleaning windshields': ['guy'], 'And then he killed himself': ['im'], 'Then I found aromatherapy So I know exactly how you feel': ['exactly'], 'The word youre looking for is': ['youre'], 'Ready to jump out of the plane with no parachute': ['parachute'], ' Kind of a symbolic gesture  Rachel that was a library card': ['gesture'], 'If you listen closely you can hear a thousand retailers scream': ['scream'], 'It sucks Youre gonna love it': ['sucks'], 'Thats it Are you going to crash on the couch': ['couch'], ' No I gotta go home sometime  Are you gonna be okay': ['im'], ' Im sorry Have it I dont want it  Split it': ['dont'], 'You probably didnt know this but in high school': ['didnt'], 'I had a major crush on you': ['crush'], 'You did': ['id'], 'I figured you thought I was Monicas geeky brother': ['geeky'], 'I did': ['id'], 'Try not to let my vulnerability become a factor here': ['factor'], 'Do you think it would be okay if I asked you out sometime': ['im'], 'Okay maybe I will': ['ill'], 'I just grabbed a spoon': ['grabbed'], ' I cant believe what Im hearing  Cant believe what Im hearing': ['hearing'], ' What I said   What I said': ['id'], 'I said you had a nice butt Its just not a great butt': ['butt'], ' You wont know a butt if it bit you  Theres an image': ['im'], 'You made it or youre serving it': ['serving'], ' Im just serving it  Ill have a cup of coffee': ['serving'], 'Kids new dream': ['id'], 'Could you give this to that guy over there': ['guy']}\n",
      "{'00:00:55,422': ['guy'], '00:00:59,459': ['guy'], '00:01:01,795': ['im'], '00:01:06,833': ['hairpiece'], '00:01:11,171': ['chalk'], '00:01:13,773': ['dont'], '00:01:17,243': ['date'], '00:01:26,119': ['date'], '00:01:31,057': ['cafeteria'], '00:01:33,660': ['realize'], '00:01:39,299': ['phone'], '00:01:51,611': ['starts'], '00:01:56,416': ['looking'], '00:01:59,619': ['looking'], '00:02:03,156': ['figure'], '00:02:07,127': ['turns'], '00:02:11,131': ['calls'], '00:02:24,844': ['ill'], '00:02:30,550': ['pulled'], '00:02:35,421': ['tied'], '00:02:40,360': ['stuff'], '00:02:49,769': ['dont'], '00:02:55,074': ['murky'], '00:03:00,113': ['dont'], '00:03:03,883': ['dont'], '00:03:07,487': ['lesbian'], '00:03:15,862': ['fixating'], '00:03:20,366': ['didnt'], '00:03:24,938': ['im'], '00:03:29,475': ['loud'], '00:03:33,913': ['las'], '00:03:39,152': ['bing'], '00:03:42,989': ['grandchildren'], '00:03:49,062': ['youre'], '00:03:53,066': ['hurting'], '00:03:58,304': ['joints'], '00:04:01,741': ['youre'], '00:04:05,311': ['dont'], '00:04:07,747': ['married'], '00:04:15,455': ['ill'], '00:04:28,835': ['guy'], '00:04:37,343': ['survivor'], '00:04:57,230': ['bridesmaids'], '00:05:03,102': ['started'], '00:05:08,107': ['presents'], '00:05:10,977': ['im'], '00:05:18,718': ['wee'], '00:05:22,288': ['gravy'], '00:05:26,392': ['freaked'], '00:05:29,462': ['looks'], '00:05:32,932': ['familiar'], '00:05:38,738': ['wondering'], '00:05:46,212': ['didnt'], '00:05:50,783': ['youre'], '00:05:53,786': ['wasnt'], '00:06:15,641': ['guess'], '00:06:21,180': ['la'], '00:06:30,223': ['im'], '00:06:34,026': ['im'], '00:06:39,132': ['matters'], '00:06:44,771': ['ill'], '00:06:51,310': ['pants'], '00:06:55,014': ['stairs'], '00:06:57,183': ['stairs'], '00:07:07,560': ['ones'], '00:07:14,600': ['dont'], '00:07:17,870': ['purse'], '00:07:24,076': ['dont'], '00:07:26,712': ['metaphor'], '00:07:30,616': ['hed'], '00:07:39,058': ['maybe'], '00:07:44,764': ['guess'], '00:07:48,634': ['maybe'], '00:07:52,104': ['dont'], '00:07:54,874': ['maybe'], '00:08:07,954': ['things'], '00:08:10,756': ['kittens'], '00:08:14,694': ['mittens'], '00:08:19,699': ['noodles'], '00:08:27,540': ['helped'], '00:08:43,656': ['ive'], '00:08:49,061': ['hitting'], '00:08:52,098': ['theres'], '00:08:59,939': ['dont'], '00:09:05,478': ['im'], '00:09:09,115': ['guy'], '00:09:12,952': ['guy'], '00:09:16,455': ['finally'], '00:09:21,827': ['cancel'], '00:09:34,206': ['guy'], '00:09:41,213': ['complains'], '00:09:51,924': ['guy'], '00:09:57,496': ['gotta'], '00:10:03,402': ['hang'], '00:10:04,937': ['seconds'], '00:10:11,277': ['las'], '00:10:19,352': ['heres'], '00:10:21,921': ['spot'], '00:10:26,726': ['starts'], '00:10:36,502': ['supposed'], '00:10:44,210': ['getting'], '00:10:47,446': ['im'], '00:10:53,285': ['liza'], '00:10:59,225': ['dont'], '00:11:02,128': ['helping'], '00:11:08,534': ['hang'], '00:11:16,008': ['dont'], '00:11:27,720': ['wee'], '00:11:39,865': ['pigeon'], '00:12:01,187': ['things'], '00:12:05,524': ['guy'], '00:12:09,762': ['guy'], '00:12:14,533': ['legs'], '00:12:20,840': ['bookcase'], '00:12:26,612': ['bracket'], '00:12:32,051': ['goes'], '00:12:38,090': ['finished'], '00:12:44,563': ['favorite'], '00:12:48,634': ['drank'], '00:12:55,975': ['dont'], '00:13:02,982': ['stereo'], '00:13:07,520': ['id'], '00:13:09,555': ['guy'], '00:13:12,825': ['idiot'], '00:13:17,630': ['im'], '00:13:22,401': ['teeth'], '00:13:24,937': ['brothers'], '00:13:27,473': ['id'], '00:13:29,275': ['valuable'], '00:13:39,285': ['broke'], '00:13:42,021': ['towel'], '00:13:53,866': ['isnt'], '00:14:16,689': ['lucky'], '00:14:21,861': ['isnt'], '00:14:25,798': ['id'], '00:14:32,705': ['divorced'], '00:14:34,473': ['divorced'], '00:14:45,251': ['took'], '00:14:48,621': ['las'], '00:15:00,165': ['ripped'], '00:15:05,671': ['dont'], '00:15:09,575': ['dont'], '00:15:13,212': ['theres'], '00:15:17,549': ['thats'], '00:15:20,886': ['tuna'], '00:15:27,793': ['talking'], '00:15:31,764': ['theres'], '00:15:35,467': ['heres'], '00:15:39,805': ['ill'], '00:15:44,743': ['im'], '00:15:52,284': ['married'], '00:16:01,260': ['dont'], '00:16:09,702': ['walked'], '00:16:15,441': ['noodles'], '00:16:18,077': ['date'], '00:16:23,015': ['theres'], '00:16:43,569': ['perform'], '00:16:47,072': ['sexually'], '00:16:54,279': ['spit'], '00:17:05,224': ['smashed'], '00:17:09,995': ['ill'], '00:17:21,273': ['gathered'], '00:17:32,384': ['im'], '00:17:37,990': ['loved'], '00:17:46,899': ['grabbed'], '00:17:50,569': ['ill'], '00:17:58,544': ['gotta'], '00:18:01,847': ['date'], '00:18:06,885': ['scream'], '00:18:10,456': ['thank'], '00:18:53,999': ['la'], '00:18:56,702': ['isnt'], '00:19:01,039': ['theres'], '00:19:06,345': ['omelet'], '00:19:41,847': ['graduations'], '00:19:46,585': ['scene'], '00:19:55,027': ['la'], '00:20:10,509': ['date'], '00:20:14,012': ['date'], '00:20:24,022': ['dont'], '00:20:32,598': ['guy'], '00:20:36,435': ['stuff'], '00:20:43,141': ['seen'], '00:20:47,446': ['regional'], '00:20:50,015': ['production'], '00:20:53,685': ['theater'], '00:20:58,590': ['ive'], '00:21:03,996': ['ill'], '00:21:08,033': ['wooden'], '00:21:13,138': ['hes'], '00:21:24,416': ['smiling'], '00:21:28,520': ['hanger'], '00:21:44,303': ['feelings'], '00:21:48,907': ['im'], '00:21:55,847': ['getting'], '00:21:59,618': ['im'], '00:22:10,128': ['things'], '00:22:27,379': ['didnt'], '00:22:34,986': ['youre'], '00:22:44,496': ['guy'], '00:22:53,105': ['credit'], '00:22:55,407': ['snap'], '00:23:02,981': ['line'], '00:23:08,787': ['sophisticated'], '00:23:17,863': ['dont'], '00:23:23,902': ['dogs'], '00:23:27,706': ['problems'], '00:23:30,575': ['ive'], '00:23:46,358': ['didnt'], '00:23:55,867': ['trained'], '00:24:00,439': ['upbeat'], '00:24:04,576': ['boots'], '00:24:08,046': ['002413275'], '00:24:14,419': ['dont'], '00:24:17,155': ['boots'], '00:24:20,625': ['id'], '00:24:23,361': ['pays'], '00:24:31,803': ['im'], '00:24:35,540': ['parents'], '00:24:37,976': ['married'], '00:24:42,380': ['ive'], '00:24:50,655': ['ill'], '00:24:53,725': ['didnt'], '00:24:55,961': ['guy'], '00:25:00,765': ['im'], '00:25:02,767': ['exactly'], '00:25:10,742': ['youre'], '00:25:24,389': ['parachute'], '00:25:47,379': ['gesture'], '00:25:58,123': ['scream'], '00:26:08,066': ['sucks'], '00:26:19,210': ['couch'], '00:26:22,447': ['im'], '00:26:55,780': ['dont'], '00:27:04,923': ['didnt'], '00:27:08,760': ['crush'], '00:27:14,099': ['id'], '00:27:17,435': ['geeky'], '00:27:21,172': ['id'], '00:27:29,681': ['factor'], '00:27:35,320': ['im'], '00:27:51,670': ['ill'], '00:28:23,068': ['grabbed'], '00:28:33,478': ['hearing'], '00:28:37,816': ['id'], '00:28:46,357': ['butt'], '00:28:50,962': ['im'], '00:29:01,906': ['serving'], '00:29:04,342': ['serving'], '00:29:08,146': ['id'], '00:29:14,252': ['guy']}\n",
      "{'00:00:59,256': ['guy'], '00:01:01,586': ['guy'], '00:01:04,389': ['im'], '00:01:09,358': ['hairpiece'], '00:01:13,605': ['chalk'], '00:01:17,072': ['dont'], '00:01:21,339': ['date'], '00:01:29,213': ['date'], '00:01:33,491': ['cafeteria'], '00:01:36,891': ['realize'], '00:01:42,757': ['phone'], '00:01:56,207': ['starts'], '00:01:59,408': ['looking'], '00:02:02,179': ['looking'], '00:02:06,922': ['figure'], '00:02:10,927': ['turns'], '00:02:15,090': ['calls'], '00:02:27,472': ['ill'], '00:02:35,214': ['pulled'], '00:02:39,858': ['tied'], '00:02:42,954': ['stuff'], '00:02:54,866': ['dont'], '00:02:59,704': ['murky'], '00:03:03,674': ['dont'], '00:03:07,284': ['dont'], '00:03:10,251': ['lesbian'], '00:03:18,797': ['fixating'], '00:03:23,893': ['didnt'], '00:03:28,897': ['im'], '00:03:31,670': ['loud'], '00:03:37,747': ['las'], '00:03:42,781': ['bing'], '00:03:47,619': ['grandchildren'], '00:03:52,862': ['youre'], '00:03:55,694': ['hurting'], '00:03:59,601': ['joints'], '00:04:04,141': ['youre'], '00:04:07,541': ['dont'], '00:04:11,274': ['married'], '00:04:19,084': ['ill'], '00:04:32,601': ['guy'], '00:04:40,744': ['survivor'], '00:05:01,894': ['bridesmaids'], '00:05:07,903': ['started'], '00:05:10,769': ['presents'], '00:05:16,677': ['im'], '00:05:19,912': ['wee'], '00:05:26,190': ['gravy'], '00:05:29,259': ['freaked'], '00:05:32,260': ['looks'], '00:05:36,368': ['familiar'], '00:05:42,139': ['wondering'], '00:05:50,114': ['didnt'], '00:05:53,616': ['youre'], '00:05:59,156': ['wasnt'], '00:06:20,544': ['guess'], '00:06:23,774': ['la'], '00:06:33,522': ['im'], '00:06:38,929': ['im'], '00:06:43,159': ['matters'], '00:06:50,300': ['ill'], '00:06:54,802': ['pants'], '00:06:56,675': ['stairs'], '00:07:00,050': ['stairs'], '00:07:11,792': ['ones'], '00:07:17,626': ['dont'], '00:07:20,896': ['purse'], '00:07:26,476': ['dont'], '00:07:29,977': ['metaphor'], '00:07:34,074': ['hed'], '00:07:42,653': ['maybe'], '00:07:48,097': ['guess'], '00:07:51,899': ['maybe'], '00:07:54,299': ['dont'], '00:07:57,707': ['maybe'], '00:08:10,445': ['things'], '00:08:14,248': ['kittens'], '00:08:18,858': ['mittens'], '00:08:23,396': ['noodles'], '00:08:30,100': ['helped'], '00:08:47,251': ['ive'], '00:08:51,723': ['hitting'], '00:08:55,261': ['theres'], '00:09:03,431': ['dont'], '00:09:08,936': ['im'], '00:09:11,583': ['guy'], '00:09:16,285': ['guy'], '00:09:18,946': ['finally'], '00:09:25,263': ['cancel'], '00:09:38,199': ['guy'], '00:09:43,977': ['complains'], '00:09:55,792': ['guy'], '00:10:00,624': ['gotta'], '00:10:04,733': ['hang'], '00:10:07,371': ['seconds'], '00:10:15,577': ['las'], '00:10:21,752': ['heres'], '00:10:26,517': ['spot'], '00:10:29,559': ['starts'], '00:10:40,233': ['supposed'], '00:10:47,270': ['getting'], '00:10:50,415': ['im'], '00:10:56,584': ['liza'], '00:11:01,955': ['dont'], '00:11:05,689': ['helping'], '00:11:11,731': ['hang'], '00:11:19,705': ['dont'], '00:11:33,681': ['wee'], '00:11:44,268': ['pigeon'], '00:12:05,317': ['things'], '00:12:08,322': ['guy'], '00:12:14,324': ['guy'], '00:12:17,331': ['legs'], '00:12:24,537': ['bookcase'], '00:12:31,675': ['bracket'], '00:12:36,147': ['goes'], '00:12:41,321': ['finished'], '00:12:47,691': ['favorite'], '00:12:52,536': ['drank'], '00:13:01,174': ['dont'], '00:13:07,316': ['stereo'], '00:13:09,351': ['id'], '00:13:12,649': ['guy'], '00:13:17,421': ['idiot'], '00:13:22,192': ['im'], '00:13:24,733': ['teeth'], '00:13:27,269': ['brothers'], '00:13:28,997': ['id'], '00:13:32,733': ['valuable'], '00:13:41,810': ['broke'], '00:13:46,253': ['towel'], '00:13:59,236': ['isnt'], '00:14:21,649': ['lucky'], '00:14:25,592': ['isnt'], '00:14:30,235': ['id'], '00:14:34,263': ['divorced'], '00:14:40,605': ['divorced'], '00:14:47,617': ['took'], '00:14:54,856': ['las'], '00:15:05,467': ['ripped'], '00:15:08,663': ['dont'], '00:15:13,011': ['dont'], '00:15:17,342': ['theres'], '00:15:20,677': ['thats'], '00:15:25,823': ['tuna'], '00:15:31,092': ['talking'], '00:15:35,291': ['theres'], '00:15:39,631': ['heres'], '00:15:43,901': ['ill'], '00:15:49,043': ['im'], '00:15:56,118': ['married'], '00:16:05,492': ['dont'], '00:16:12,796': ['walked'], '00:16:17,875': ['noodles'], '00:16:22,810': ['date'], '00:16:27,509': ['theres'], '00:16:46,367': ['perform'], '00:16:48,903': ['sexually'], '00:16:58,716': ['spit'], '00:17:09,092': ['smashed'], '00:17:14,989': ['ill'], '00:17:26,108': ['gathered'], '00:17:36,480': ['im'], '00:17:43,986': ['loved'], '00:17:50,232': ['grabbed'], '00:17:54,938': ['ill'], '00:18:01,638': ['gotta'], '00:18:06,682': ['date'], '00:18:10,286': ['scream'], '00:18:15,120': ['thank'], '00:18:56,331': ['la'], '00:19:00,433': ['isnt'], '00:19:06,170': ['theres'], '00:19:11,009': ['omelet'], '00:19:46,375': ['graduations'], '00:19:49,110': ['scene'], '00:19:56,426': ['la'], '00:20:13,808': ['date'], '00:20:17,243': ['date'], '00:20:29,551': ['dont'], '00:20:35,192': ['guy'], '00:20:40,997': ['stuff'], '00:20:47,271': ['seen'], '00:20:49,812': ['regional'], '00:20:53,473': ['production'], '00:20:56,483': ['theater'], '00:21:01,218': ['ive'], '00:21:07,762': ['ill'], '00:21:10,695': ['wooden'], '00:21:17,336': ['hes'], '00:21:28,318': ['smiling'], '00:21:33,048': ['hanger'], '00:21:48,034': ['feelings'], '00:21:51,876': ['im'], '00:21:59,408': ['getting'], '00:22:04,248': ['im'], '00:22:14,531': ['things'], '00:22:30,542': ['didnt'], '00:22:39,013': ['youre'], '00:22:47,863': ['guy'], '00:22:55,198': ['credit'], '00:22:59,707': ['snap'], '00:23:05,541': ['line'], '00:23:12,052': ['sophisticated'], '00:23:21,993': ['dont'], '00:23:27,531': ['dogs'], '00:23:30,402': ['problems'], '00:23:33,874': ['ive'], '00:23:50,419': ['didnt'], '00:24:00,167': ['trained'], '00:24:04,398': ['upbeat'], '00:24:07,841': ['boots'], '00:24:10,037': ['002413275'], '00:24:16,944': ['dont'], '00:24:19,214': ['boots'], '00:24:22,820': ['id'], '00:24:26,023': ['pays'], '00:24:35,330': ['im'], '00:24:37,770': ['parents'], '00:24:41,707': ['married'], '00:24:45,508': ['ive'], '00:24:53,522': ['ill'], '00:24:55,750': ['didnt'], '00:25:00,557': ['guy'], '00:25:02,562': ['im'], '00:25:07,431': ['exactly'], '00:25:13,336': ['youre'], '00:25:27,290': ['parachute'], '00:25:51,440': ['gesture'], '00:26:02,992': ['scream'], '00:26:11,297': ['sucks'], '00:26:22,270': ['couch'], '00:26:26,611': ['im'], '00:27:00,683': ['dont'], '00:27:08,381': ['didnt'], '00:27:11,251': ['crush'], '00:27:17,159': ['id'], '00:27:20,962': ['geeky'], '00:27:23,231': ['id'], '00:27:34,675': ['factor'], '00:27:39,450': ['im'], '00:27:53,604': ['ill'], '00:28:27,368': ['grabbed'], '00:28:37,642': ['hearing'], '00:28:40,046': ['id'], '00:28:50,794': ['butt'], '00:28:55,194': ['im'], '00:29:04,136': ['serving'], '00:29:07,937': ['serving'], '00:29:09,613': ['id'], '00:29:17,983': ['guy']}\n"
     ]
    }
   ],
   "source": [
    "print(word_to_dialogue_indices)\n",
    "print(word_to_starttime_indices)\n",
    "print(word_to_endtime_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n",
      "140\n",
      "140\n"
     ]
    }
   ],
   "source": [
    "print(len(unique_word_to_dialogue_indices))\n",
    "print(len(unique_word_to_starttime_indices))\n",
    "print(len(unique_word_to_endtime_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting the repetetive values of the dictionary\n",
    "\n",
    "unique_word_to_dialogue_indices = {}\n",
    "unique_word_to_starttime_indices = {}\n",
    "unique_word_to_endtime_indices = {}\n",
    "\n",
    "for key, value in word_to_dialogue_indices.items():\n",
    "    if value not in unique_word_to_dialogue_indices.values():\n",
    "        unique_word_to_dialogue_indices[key] = value\n",
    "\n",
    "for key, value in word_to_starttime_indices.items():\n",
    "    if value not in unique_word_to_starttime_indices.values():\n",
    "        unique_word_to_starttime_indices[key] = value\n",
    "\n",
    "for key, value in word_to_endtime_indices.items():\n",
    "    if value not in unique_word_to_endtime_indices.values():\n",
    "        unique_word_to_endtime_indices[key] = value     \n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Theres nothing to tell Its just some guy I work with': ['guy'], 'There has to be something wrong with him': ['im'], 'So does he have a hump and a hairpiece': ['hairpiece'], 'Wait does he eat chalk': ['chalk'], 'I dont want her to go through what I did with Carl': ['dont'], 'Okay everybody relax This is not even a date': ['date'], 'Im in high school in the cafeteria': ['cafeteria'], 'and I realize Im totally naked': ['realize'], 'Then I look down and I realize there is a phone': ['phone'], 'All of a sudden the phone starts to ring': ['starts'], 'What do I do Everyone starts looking at me': ['looking'], 'Finally I figure Id better answer it': ['figure'], 'And it turns out its my mother': ['turns'], 'Which is very very weird because she never calls me': ['calls'], 'He says Hello I want to kill myself': ['ill'], 'I feel like someone pulled my intestine out of my mouth': ['pulled'], ' and tied it around my neck  Cookie': ['tied'], 'Carol moved her stuff out today': ['stuff'], ' Just leave my aura alone okay  Fine be murky': ['murky'], 'You never knew she was a lesbian': ['lesbian'], 'Why does everyone keep fixating on that': ['fixating'], 'She didnt know How should I know': ['didnt'], 'Did I say that out loud': ['loud'], 'I told Mom and Dad last night They took it pretty well': ['las'], 'So that hysterical phone call from a woman sobbing': ['bing'], 'Ill never have grandchildren was what A wrong number': ['grandchildren'], 'Look youre feeling a lot of pain right now': ['youre'], 'Youre angry Youre hurting': ['hurting'], 'Strip joints': ['joints'], 'I just want to be married again': ['married'], 'Everybody this is Rachel a Lincoln High survivor': ['survivor'], 'You want to tell us now or are we waiting for four wet bridesmaids': ['bridesmaids'], 'Well it started about a halfhour before the wedding': ['started'], 'I was in the room with all the presents': ['presents'], 'Sweet N Low': ['wee'], 'I realized I was more turned on by this gravy boat than Barry': ['gravy'], 'I got freaked out and it hit me': ['freaked'], 'How much Barry looks like Mr Potato Head': ['looks'], 'I always knew he looked familiar but': ['familiar'], 'I had to get out of there and I started wondering': ['wondering'], ' Who wasnt invited to the wedding  I hoped that wouldnt be an issue': ['wasnt'], 'I guess he bought her the pipe organ and shes really not happy about it': ['guess'], 'Tuna or egg salad Decide': ['la'], 'Well it matters to me': ['matters'], 'She should not be wearing those pants': ['pants'], 'Push her down the stairs': ['stairs'], 'All my life everyones always told me Youre a shoe': ['ones'], 'What if I want to be a purse': ['purse'], 'Its a metaphor Daddy': ['metaphor'], 'You can see where hed have trouble': ['hed'], 'Well maybe Ill just stay here with Monica': ['maybe'], 'Try to think of nice calm things': ['things'], 'Raindrops on roses And whiskers on kittens': ['kittens'], 'Doorbells and sleigh bells And something with mittens': ['mittens'], 'La la la something And noodles with string': ['noodles'], 'I helped': ['helped'], 'Me and Chandler live across the hall Hes away a lot': ['ive'], 'Stop hitting on her Its her wedding day': ['hitting'], 'Like theres a rule or something': ['theres'], ' He finally asked you out  Yes': ['finally'], ' Rach I can cancel  Please go Ill be fine': ['cancel'], 'Or he just complains a lot': ['complains'], 'Ill be right back Ive just gotta go': ['gotta'], 'Change': ['hang'], 'Sit down Two seconds': ['seconds'], 'Hey Paul heres a tip': ['heres'], 'She really likes it when you rub her neck in the same spot': ['spot'], 'I was supposed to be headed for Aruba on my honeymoon': ['supposed'], 'Right Youre not even getting your honeymoon': ['getting'], 'big lizards': ['liza'], 'Joey and Chandler are helping me with my furniture': ['helping'], 'Is like a giant pigeon': ['pigeon'], 'and I cannot feel my legs': ['legs'], ' We got a bookcase  Its beautiful': ['bookcase'], 'I would have to say that is an Lshaped bracket': ['bracket'], ' Which goes where  I have no idea': ['goes'], ' Done with the bookcase  All finished': ['finished'], 'This was Carols favorite beer': ['favorite'], 'She always drank it out of the can I should have known': ['drank'], 'She got the furniture the stereo the good TV': ['stereo'], 'What did you get': ['id'], ' Oh my God  I know Im such an idiot': ['idiot'], 'I mean how clean can teeth get': ['teeth'], 'My brothers going through that': ['brothers'], 'He might accidentally break something valuable of hers': ['valuable'], 'You actually broke her watch': ['broke'], 'The worst I ever did was shred my old boyfriends favorite towel': ['towel'], 'You probably think its about making love with your socks on but it isnt': ['isnt'], 'I know that some lucky girl is going to become Mrs Barry Finkel': ['lucky'], 'Im divorced': ['divorced'], 'That only took me an hour': ['took'], 'Four years of closeness and sharing after which she ripped your heart out': ['ripped'], 'I mean what if you get one woman and thats it': ['thats'], 'Unfortunately in my case there was only one woman for her': ['tuna'], 'What are you talking about One woman': ['talking'], 'Ever since she walked out on me': ['walked'], 'I havent been able to perform': ['perform'], 'sexually': ['sexually'], 'Being spit on is probably not what you need right now': ['spit'], 'Im glad you smashed her watch': ['smashed'], 'We are gathered here to join Joanie Louise Cunningham': ['gathered'], 'But Joanie loved Chachi Thats the difference': ['loved'], 'Do you know how long its been since I grabbed a spoon': ['grabbed'], 'Andreas the screamer Angela has cats': ['scream'], 'Right thanks Its Julie Im out of here': ['thank'], 'If you feel like you have to make a Western omelet or something': ['omelet'], 'Last night was like all my birthdays both graduations': ['graduations'], 'plus the barnraising scene in Witness': ['scene'], ' Yeah Im an actor  Have I seen you in anything': ['seen'], 'I doubt it Mostly regional work': ['regional'], 'Unless you saw the Wee Ones production of Pinocchio': ['production'], 'at the little theater in the park': ['theater'], 'Once I was a wooden boy A little wooden boy': ['wooden'], 'You should both know that hes a dead man': ['hes'], 'Did you talk to Barry I cant stop smiling': ['smiling'], 'I see that You look like you slept with a hanger in your mouth': ['hanger'], 'Well its like that With feelings': ['feelings'], 'What I take credit for Paul': ['credit'], 'Before me there was no snap in his turtle for two years': ['snap'], 'Of course it was a line': ['line'], 'I assume we want an answer more sophisticated than': ['sophisticated'], 'Is it like I have some sort of beacon that only dogs': ['dogs'], 'and men with emotional problems can hear': ['problems'], 'Are you kidding Im trained for nothing': ['trained'], ' I was laughed out of 12 interviews  Youre surprisingly upbeat': ['upbeat'], 'Youd be too if you found these boots on sale': ['boots'], '002410215  002413275 How well you know me': ['002413275'], 'And who pays for that': ['pays'], 'You cant live off your parents': ['parents'], 'Then I found aromatherapy So I know exactly how you feel': ['exactly'], 'Ready to jump out of the plane with no parachute': ['parachute'], ' Kind of a symbolic gesture  Rachel that was a library card': ['gesture'], 'It sucks Youre gonna love it': ['sucks'], 'Thats it Are you going to crash on the couch': ['couch'], 'I had a major crush on you': ['crush'], 'I figured you thought I was Monicas geeky brother': ['geeky'], 'Try not to let my vulnerability become a factor here': ['factor'], ' I cant believe what Im hearing  Cant believe what Im hearing': ['hearing'], 'I said you had a nice butt Its just not a great butt': ['butt'], 'You made it or youre serving it': ['serving']}\n",
      "{'00:00:55,422': ['guy'], '00:01:01,795': ['im'], '00:01:06,833': ['hairpiece'], '00:01:11,171': ['chalk'], '00:01:13,773': ['dont'], '00:01:17,243': ['date'], '00:01:31,057': ['cafeteria'], '00:01:33,660': ['realize'], '00:01:39,299': ['phone'], '00:01:51,611': ['starts'], '00:01:56,416': ['looking'], '00:02:03,156': ['figure'], '00:02:07,127': ['turns'], '00:02:11,131': ['calls'], '00:02:24,844': ['ill'], '00:02:30,550': ['pulled'], '00:02:35,421': ['tied'], '00:02:40,360': ['stuff'], '00:02:55,074': ['murky'], '00:03:07,487': ['lesbian'], '00:03:15,862': ['fixating'], '00:03:20,366': ['didnt'], '00:03:29,475': ['loud'], '00:03:33,913': ['las'], '00:03:39,152': ['bing'], '00:03:42,989': ['grandchildren'], '00:03:49,062': ['youre'], '00:03:53,066': ['hurting'], '00:03:58,304': ['joints'], '00:04:07,747': ['married'], '00:04:37,343': ['survivor'], '00:04:57,230': ['bridesmaids'], '00:05:03,102': ['started'], '00:05:08,107': ['presents'], '00:05:18,718': ['wee'], '00:05:22,288': ['gravy'], '00:05:26,392': ['freaked'], '00:05:29,462': ['looks'], '00:05:32,932': ['familiar'], '00:05:38,738': ['wondering'], '00:05:53,786': ['wasnt'], '00:06:15,641': ['guess'], '00:06:21,180': ['la'], '00:06:39,132': ['matters'], '00:06:51,310': ['pants'], '00:06:55,014': ['stairs'], '00:07:07,560': ['ones'], '00:07:17,870': ['purse'], '00:07:26,712': ['metaphor'], '00:07:30,616': ['hed'], '00:07:39,058': ['maybe'], '00:08:07,954': ['things'], '00:08:10,756': ['kittens'], '00:08:14,694': ['mittens'], '00:08:19,699': ['noodles'], '00:08:27,540': ['helped'], '00:08:43,656': ['ive'], '00:08:49,061': ['hitting'], '00:08:52,098': ['theres'], '00:09:16,455': ['finally'], '00:09:21,827': ['cancel'], '00:09:41,213': ['complains'], '00:09:57,496': ['gotta'], '00:10:03,402': ['hang'], '00:10:04,937': ['seconds'], '00:10:19,352': ['heres'], '00:10:21,921': ['spot'], '00:10:36,502': ['supposed'], '00:10:44,210': ['getting'], '00:10:53,285': ['liza'], '00:11:02,128': ['helping'], '00:11:39,865': ['pigeon'], '00:12:14,533': ['legs'], '00:12:20,840': ['bookcase'], '00:12:26,612': ['bracket'], '00:12:32,051': ['goes'], '00:12:38,090': ['finished'], '00:12:44,563': ['favorite'], '00:12:48,634': ['drank'], '00:13:02,982': ['stereo'], '00:13:07,520': ['id'], '00:13:12,825': ['idiot'], '00:13:22,401': ['teeth'], '00:13:24,937': ['brothers'], '00:13:29,275': ['valuable'], '00:13:39,285': ['broke'], '00:13:42,021': ['towel'], '00:13:53,866': ['isnt'], '00:14:16,689': ['lucky'], '00:14:32,705': ['divorced'], '00:14:45,251': ['took'], '00:15:00,165': ['ripped'], '00:15:17,549': ['thats'], '00:15:20,886': ['tuna'], '00:15:27,793': ['talking'], '00:16:09,702': ['walked'], '00:16:43,569': ['perform'], '00:16:47,072': ['sexually'], '00:16:54,279': ['spit'], '00:17:05,224': ['smashed'], '00:17:21,273': ['gathered'], '00:17:37,990': ['loved'], '00:17:46,899': ['grabbed'], '00:18:06,885': ['scream'], '00:18:10,456': ['thank'], '00:19:06,345': ['omelet'], '00:19:41,847': ['graduations'], '00:19:46,585': ['scene'], '00:20:43,141': ['seen'], '00:20:47,446': ['regional'], '00:20:50,015': ['production'], '00:20:53,685': ['theater'], '00:21:08,033': ['wooden'], '00:21:13,138': ['hes'], '00:21:24,416': ['smiling'], '00:21:28,520': ['hanger'], '00:21:44,303': ['feelings'], '00:22:53,105': ['credit'], '00:22:55,407': ['snap'], '00:23:02,981': ['line'], '00:23:08,787': ['sophisticated'], '00:23:23,902': ['dogs'], '00:23:27,706': ['problems'], '00:23:55,867': ['trained'], '00:24:00,439': ['upbeat'], '00:24:04,576': ['boots'], '00:24:08,046': ['002413275'], '00:24:23,361': ['pays'], '00:24:35,540': ['parents'], '00:25:02,767': ['exactly'], '00:25:24,389': ['parachute'], '00:25:47,379': ['gesture'], '00:26:08,066': ['sucks'], '00:26:19,210': ['couch'], '00:27:08,760': ['crush'], '00:27:17,435': ['geeky'], '00:27:29,681': ['factor'], '00:28:33,478': ['hearing'], '00:28:46,357': ['butt'], '00:29:01,906': ['serving']}\n",
      "{'00:00:59,256': ['guy'], '00:01:04,389': ['im'], '00:01:09,358': ['hairpiece'], '00:01:13,605': ['chalk'], '00:01:17,072': ['dont'], '00:01:21,339': ['date'], '00:01:33,491': ['cafeteria'], '00:01:36,891': ['realize'], '00:01:42,757': ['phone'], '00:01:56,207': ['starts'], '00:01:59,408': ['looking'], '00:02:06,922': ['figure'], '00:02:10,927': ['turns'], '00:02:15,090': ['calls'], '00:02:27,472': ['ill'], '00:02:35,214': ['pulled'], '00:02:39,858': ['tied'], '00:02:42,954': ['stuff'], '00:02:59,704': ['murky'], '00:03:10,251': ['lesbian'], '00:03:18,797': ['fixating'], '00:03:23,893': ['didnt'], '00:03:31,670': ['loud'], '00:03:37,747': ['las'], '00:03:42,781': ['bing'], '00:03:47,619': ['grandchildren'], '00:03:52,862': ['youre'], '00:03:55,694': ['hurting'], '00:03:59,601': ['joints'], '00:04:11,274': ['married'], '00:04:40,744': ['survivor'], '00:05:01,894': ['bridesmaids'], '00:05:07,903': ['started'], '00:05:10,769': ['presents'], '00:05:19,912': ['wee'], '00:05:26,190': ['gravy'], '00:05:29,259': ['freaked'], '00:05:32,260': ['looks'], '00:05:36,368': ['familiar'], '00:05:42,139': ['wondering'], '00:05:59,156': ['wasnt'], '00:06:20,544': ['guess'], '00:06:23,774': ['la'], '00:06:43,159': ['matters'], '00:06:54,802': ['pants'], '00:06:56,675': ['stairs'], '00:07:11,792': ['ones'], '00:07:20,896': ['purse'], '00:07:29,977': ['metaphor'], '00:07:34,074': ['hed'], '00:07:42,653': ['maybe'], '00:08:10,445': ['things'], '00:08:14,248': ['kittens'], '00:08:18,858': ['mittens'], '00:08:23,396': ['noodles'], '00:08:30,100': ['helped'], '00:08:47,251': ['ive'], '00:08:51,723': ['hitting'], '00:08:55,261': ['theres'], '00:09:18,946': ['finally'], '00:09:25,263': ['cancel'], '00:09:43,977': ['complains'], '00:10:00,624': ['gotta'], '00:10:04,733': ['hang'], '00:10:07,371': ['seconds'], '00:10:21,752': ['heres'], '00:10:26,517': ['spot'], '00:10:40,233': ['supposed'], '00:10:47,270': ['getting'], '00:10:56,584': ['liza'], '00:11:05,689': ['helping'], '00:11:44,268': ['pigeon'], '00:12:17,331': ['legs'], '00:12:24,537': ['bookcase'], '00:12:31,675': ['bracket'], '00:12:36,147': ['goes'], '00:12:41,321': ['finished'], '00:12:47,691': ['favorite'], '00:12:52,536': ['drank'], '00:13:07,316': ['stereo'], '00:13:09,351': ['id'], '00:13:17,421': ['idiot'], '00:13:24,733': ['teeth'], '00:13:27,269': ['brothers'], '00:13:32,733': ['valuable'], '00:13:41,810': ['broke'], '00:13:46,253': ['towel'], '00:13:59,236': ['isnt'], '00:14:21,649': ['lucky'], '00:14:34,263': ['divorced'], '00:14:47,617': ['took'], '00:15:05,467': ['ripped'], '00:15:20,677': ['thats'], '00:15:25,823': ['tuna'], '00:15:31,092': ['talking'], '00:16:12,796': ['walked'], '00:16:46,367': ['perform'], '00:16:48,903': ['sexually'], '00:16:58,716': ['spit'], '00:17:09,092': ['smashed'], '00:17:26,108': ['gathered'], '00:17:43,986': ['loved'], '00:17:50,232': ['grabbed'], '00:18:10,286': ['scream'], '00:18:15,120': ['thank'], '00:19:11,009': ['omelet'], '00:19:46,375': ['graduations'], '00:19:49,110': ['scene'], '00:20:47,271': ['seen'], '00:20:49,812': ['regional'], '00:20:53,473': ['production'], '00:20:56,483': ['theater'], '00:21:10,695': ['wooden'], '00:21:17,336': ['hes'], '00:21:28,318': ['smiling'], '00:21:33,048': ['hanger'], '00:21:48,034': ['feelings'], '00:22:55,198': ['credit'], '00:22:59,707': ['snap'], '00:23:05,541': ['line'], '00:23:12,052': ['sophisticated'], '00:23:27,531': ['dogs'], '00:23:30,402': ['problems'], '00:24:00,167': ['trained'], '00:24:04,398': ['upbeat'], '00:24:07,841': ['boots'], '00:24:10,037': ['002413275'], '00:24:26,023': ['pays'], '00:24:37,770': ['parents'], '00:25:07,431': ['exactly'], '00:25:27,290': ['parachute'], '00:25:51,440': ['gesture'], '00:26:11,297': ['sucks'], '00:26:22,270': ['couch'], '00:27:11,251': ['crush'], '00:27:20,962': ['geeky'], '00:27:34,675': ['factor'], '00:28:37,642': ['hearing'], '00:28:50,794': ['butt'], '00:29:04,136': ['serving']}\n"
     ]
    }
   ],
   "source": [
    "print(unique_word_to_dialogue_indices) \n",
    "print(unique_word_to_starttime_indices) \n",
    "print(unique_word_to_endtime_indices) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from Extraction import Model\n",
    "\n",
    "reload(Extraction)\n",
    "\n",
    "WordExtraction = Extraction.Model()\n",
    "\n",
    "initialwords = []\n",
    "\n",
    "# for i in range(len(new_dialogues)):\n",
    "\n",
    "#     initialwords.append(WordExtraction.WordFilter(new_dialogues[i]))\n",
    "#     initialwords = [x for x in initialwords if x]\n",
    "# initialwords = list(itertools.chain(*initialwords))\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(len(new_dialogues)):\n",
    "#     filtered_words = WordExtraction.WordFilter(new_dialogues[i])\n",
    "#     filtered_tuple = tuple(filtered_words)\n",
    "#     initialwords.add(filtered_tuple)\n",
    "\n",
    "# Convert set to list and eliminate duplicates\n",
    "# initialwords = list(set(initialwords))\n",
    "\n",
    "wordcount = 0\n",
    "\n",
    "with open('test.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['Word', 'Translation', 'Meaning', 'Example Sentence', 'Tag', 'Dialogue', 'Start Time', 'End Time']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    for i in range(len(new_dialogues)):\n",
    "        for dialogue, word in unique_word_to_dialogue_indices.items():         \n",
    "            # if word in new_dialogues[i]:\n",
    "            # wordcount += 1\n",
    "            # print(i)\n",
    "            # print(word)\n",
    "            try:\n",
    "                translated, meaning = WordExtraction.Translator(word)\n",
    "                example = WordExtraction.Example(word)\n",
    "\n",
    "                writer.writerow({\n",
    "                    'Word': word,\n",
    "                    'Translation': translated,\n",
    "                    'Meaning': meaning,\n",
    "                    'Example Sentence': example,\n",
    "                    'Tag' : tag,\n",
    "                    'Dialogue' : dialogue,\n",
    "                    'Start Time' : start_times[i],\n",
    "                    'End Time' : end_times[i]\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred while translating word '{word}': {e}\")\n",
    "                continue  # Skip to the next word if translation fails\n",
    "\n",
    "print(wordcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(Extraction)\n",
    "WordExtraction = Extraction.Model()\n",
    "\n",
    "# initialwords = []\n",
    "\n",
    "# initialwords = list(initialwords)\n",
    "# wordcount = 0\n",
    "\n",
    "with open('season.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['Word', 'Translation', 'Meaning', 'Example Sentence', 'Tag', 'Dialogue', 'Start Time', 'End Time']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    for diag, starttime, endtime in zip(unique_word_to_dialogue_indices.keys(), unique_word_to_starttime_indices.keys(), unique_word_to_endtime_indices.keys()):\n",
    "        # input(unique_word_to_dialogue_indices[key])\n",
    "        # initialwords.append(WordExtraction.WordFilter(new_dialogues[i]))\n",
    "        # input(initialwords[0])\n",
    "        # initialwords = [x for x in initialwords if x]\n",
    "        # initialwords = list(itertools.chain(*initialwords))\n",
    "        # input(initialwords)\n",
    "            # for word in initialwords: #300         300 \n",
    "        # print(diag)\n",
    "        # print(starttime)\n",
    "        # print(endtime)\n",
    "        try:\n",
    "            translated, meaning = WordExtraction.Translator(unique_word_to_dialogue_indices[diag][0])\n",
    "            # input(translated)\n",
    "            # input(unique_word_to_dialogue_indices[diag][0])\n",
    "            # input(meaning)\n",
    "            example = WordExtraction.Example(unique_word_to_dialogue_indices[diag][0])\n",
    "\n",
    "            writer.writerow({\n",
    "                'Word': unique_word_to_dialogue_indices[diag][0],\n",
    "                'Translation': translated, \n",
    "                'Meaning': meaning,\n",
    "                'Example Sentence': example,\n",
    "                'Tag' : tag,\n",
    "                'Dialogue' : diag,\n",
    "                'Start Time' : starttime,\n",
    "                'End Time' : endtime\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            \n",
    "            print(f\"Error occurred while translating word '{word}': {e}\")\n",
    "            continue  # Skip to the next word if translation fails\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loadSubtitle import loadSubtitle\n",
    "import Extraction \n",
    "from importlib import reload\n",
    "import string\n",
    "import csv\n",
    "import itertools\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "reload(Extraction)\n",
    "\n",
    "WordExtraction = Extraction.Model()\n",
    "load = loadSubtitle()\n",
    "seasons, file_adresess = load.loadseasons('english')\n",
    "load.process_subtitles('english')\n",
    "\n",
    "season_dir = input('please enter the season name: ')\n",
    "file_adresess = []\n",
    "\n",
    "for filename in glob.glob(f'english/{season_dir}/*.srt'):\n",
    "    file_adresess.append(filename)\n",
    "file_adresess.sort()\n",
    "\n",
    "\n",
    "count = 0\n",
    "\n",
    "for path in file_adresess:\n",
    "\n",
    "    count+=1\n",
    "\n",
    "    matches, dialogues, start_times, end_times  = WordExtraction.DialogueExtraction(path)\n",
    "\n",
    "    tag, time = WordExtraction.tag(file_adresess[0], season_dir)\n",
    "    # translateds = []\n",
    "    # initialwords = []\n",
    "    # meanings = []\n",
    "    # example_sentences = []\n",
    "\n",
    "    new_dialogues = WordExtraction.RemovePuncs(dialogues)\n",
    "\n",
    "    initialwords = []\n",
    "\n",
    "    for i in range(len(new_dialogues)):\n",
    "\n",
    "        initialwords.append(WordExtraction.WordFilter(new_dialogues[i]))\n",
    "        initialwords = [x for x in initialwords if x]\n",
    "    initialwords = list(itertools.chain(*initialwords))\n",
    "\n",
    "    word_to_dialogue_indices = {}\n",
    "    word_to_starttime_indices = {}\n",
    "    word_to_endtime_indices = {}\n",
    "\n",
    "    for dialogue,start_time,end_time in zip(dialogues,start_times,end_times):\n",
    "        for word in initialwords:\n",
    "            if word in dialogue:\n",
    "                # if word not in word_to_dialogue_indices:\n",
    "                word_to_dialogue_indices[dialogue] = [word]\n",
    "                word_to_starttime_indices[start_time] = [word]\n",
    "                word_to_endtime_indices[end_time] = [word]\n",
    "                \n",
    "            else:\n",
    "                continue\n",
    "\n",
    "\n",
    "    # deleting the repetetive values of the dictionary\n",
    "\n",
    "    unique_word_to_dialogue_indices = {}\n",
    "    unique_word_to_starttime_indices = {}\n",
    "    unique_word_to_endtime_indices = {}\n",
    "\n",
    "    for key, value in word_to_dialogue_indices.items():\n",
    "        if value not in unique_word_to_dialogue_indices.values():\n",
    "            unique_word_to_dialogue_indices[key] = value\n",
    "\n",
    "    for key, value in word_to_starttime_indices.items():\n",
    "        if value not in unique_word_to_starttime_indices.values():\n",
    "            unique_word_to_starttime_indices[key] = value\n",
    "\n",
    "    for key, value in word_to_endtime_indices.items():\n",
    "        if value not in unique_word_to_endtime_indices.values():\n",
    "            unique_word_to_endtime_indices[key] = value  \n",
    "\n",
    "\n",
    "    # initialwords = []\n",
    "\n",
    "    # initialwords = list(initialwords)\n",
    "    # wordcount = 0\n",
    "\n",
    "    with open(f'{season_dir}.csv', 'a', newline='') as csvfile:\n",
    "        fieldnames = ['Word', 'Translation', 'Meaning','Synonyms','Example Sentence', 'Tag', 'Dialogue', 'Start Time', 'End Time']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        is_empty = csvfile.tell() == 0\n",
    "\n",
    "        if is_empty:\n",
    "            writer.writeheader()\n",
    "        \n",
    "        for diag, starttime, endtime in zip(unique_word_to_dialogue_indices.keys(), unique_word_to_starttime_indices.keys(), unique_word_to_endtime_indices.keys()):\n",
    "\n",
    "            try:\n",
    "                meaning,synonyms = WordExtraction.Translator(unique_word_to_dialogue_indices[diag][0])\n",
    "                persianmean = WordExtraction.persian_mean(unique_word_to_dialogue_indices[diag][0])\n",
    "                json =  WordExtraction.JSON(unique_word_to_dialogue_indices[diag][0])\n",
    "\n",
    "                example = WordExtraction.Example(unique_word_to_dialogue_indices[diag][0])\n",
    "\n",
    "                if meaning is not None and meaning != {} and example is not None and example != [] and example != {} and example != '':\n",
    "\n",
    "                    writer.writerow({\n",
    "                        'Word': unique_word_to_dialogue_indices[diag][0],\n",
    "                        'Translation': persianmean, \n",
    "                        'Meaning': meaning,\n",
    "                        'Synonyms': synonyms,\n",
    "                        'Example Sentence': example,\n",
    "                        'Tag' : f'{season_dir},episode {count}',\n",
    "                        'Dialogue' : diag,\n",
    "                        'Start Time' : starttime,\n",
    "                        'End Time' : endtime,\n",
    "                        'JSON_OUTPUT' : json\n",
    "                    })\n",
    "                \n",
    "            except Exception as e:\n",
    "                # print(f\"Error occurred while translating word '{word}': {e}\")\n",
    "                continue  # Skip to the next word if translation fails\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(f'{season_dir}.csv')\n",
    "\n",
    "df.drop_duplicates(subset='Word', inplace=True)\n",
    "\n",
    "df.to_csv(f'{season_dir}_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'realize',\n",
       " 'seeAlsos': None,\n",
       " 'typeToMeanings': {'فعل': {'meanings': ['تحقق بخشیدن',\n",
       "    'تصدیق کردن',\n",
       "    'پذیرفتن',\n",
       "    'فهمیدن',\n",
       "    'به پول نقد تبدیل کردن',\n",
       "    'پی بردن',\n",
       "    'تحقق یافتن',\n",
       "    'درک کردن',\n",
       "    'قوه اوردن',\n",
       "    'واقعی کردن',\n",
       "    'دریافتن',\n",
       "    'نقد کردن'],\n",
       "   'definitionExamples': [{'definition': 'become fully aware of (something) as a fact; understand clearly.',\n",
       "     'example': 'he realized his mistake at once',\n",
       "     'synonyms': ['register',\n",
       "      'perceive',\n",
       "      'discern',\n",
       "      'be/become aware of (the fact that)',\n",
       "      'be/become conscious of (the fact that)',\n",
       "      'notice',\n",
       "      'understand',\n",
       "      'grasp',\n",
       "      'comprehend',\n",
       "      'see',\n",
       "      'recognize',\n",
       "      'work out',\n",
       "      'fathom',\n",
       "      'apprehend',\n",
       "      'latch on to',\n",
       "      'savvy',\n",
       "      'figure out',\n",
       "      'get (the message)',\n",
       "      'suss',\n",
       "      'be/become cognizant of']},\n",
       "    {'definition': 'cause (something desired or anticipated) to happen.',\n",
       "     'example': 'our loans are helping small business realize their dreams',\n",
       "     'synonyms': []},\n",
       "    {'definition': 'give actual or physical form to.',\n",
       "     'example': 'the stage designs have been beautifully realized',\n",
       "     'synonyms': []},\n",
       "    {'definition': 'make (money or a profit) from a transaction.',\n",
       "     'example': ',\"she realized a profit of \\r\\n\\t\\t\\t\\t100,000\"',\n",
       "     'synonyms': ['make', 'clear', 'gain', 'earn', 'return', 'produce']}]}},\n",
       " 'notFound': False}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "word = 'realize'\n",
    "api_url = \"https://www.faraazin.ir/api/dictionary\"\n",
    "params = {\"text\": word}\n",
    "\n",
    "response = requests.get(api_url, params=params)\n",
    "data = response.json()\n",
    "\n",
    "# Assuming you have the JSON response stored in the variable 'response'\n",
    "\n",
    "# type_to_meanings = data['typeToMeanings']\n",
    "\n",
    "# # Create a list to store the categorized meanings\n",
    "# categorized_meanings = []\n",
    "\n",
    "# # Iterate over each type and extract the meanings\n",
    "# for word_type, meanings_info in type_to_meanings.items():\n",
    "#     meanings = meanings_info['meanings']\n",
    "#     categorized_meanings.append(f'{word_type}: {meanings}')\n",
    "\n",
    "# # Join the categorized meanings into a single string\n",
    "# output = '\\n'.join(categorized_meanings)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
